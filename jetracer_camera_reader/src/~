#include "ONNXDetector.h"
#include <fstream>
#include <iostream>
#include <NvOnnxParser.h>

void Logger::log(Severity severity, const char* msg) noexcept {
    if (severity <= Severity::kWARNING) {
        std::cout << msg << std::endl;
    }
}

ONNXDetector::ONNXDetector(const std::string& modelPath, float confThreshold)
    : mModelPath(modelPath)
    , mConfThreshold(confThreshold)
    , mInputH(300)
    , mInputW(300)
    , mInputC(3)
    , mCudaBuffer{nullptr, nullptr}
    , mCudaStream(nullptr) {
    
    // Tạo CUDA stream
    cudaStreamCreate(&mCudaStream);
    
    // Tải class names
    loadClassNames("/home/jetson/models/labels.txt");
    
    // Xây dựng engine
    if (!buildEngine()) {
        std::cerr << "Failed to build TensorRT engine" << std::endl;
        return;
    }
    
    // Cấp phát bộ nhớ cho buffers
    mInputSize = mInputH * mInputW * mInputC;
    mHostInputBuffer.resize(mInputSize);
    
    // Lấy kích thước output
    // SSD MobileNet có 1 output với số lượng detections * 7 (image_id, label, confidence, xmin, ymin, xmax, ymax)
    mOutputSize = 100 * 7; // Điều chỉnh số lượng kết quả phát hiện tối đa
    mHostOutputBuffer.resize(mOutputSize);
    
    // Cấp phát bộ nhớ CUDA
    cudaMalloc(&mCudaBuffer[0], mInputSize * sizeof(float));
    cudaMalloc(&mCudaBuffer[1], mOutputSize * sizeof(float));
}

ONNXDetector::~ONNXDetector() {
    // Giải phóng bộ nhớ CUDA
    cudaFree(mCudaBuffer[0]);
    cudaFree(mCudaBuffer[1]);
    cudaStreamDestroy(mCudaStream);
}

bool ONNXDetector::buildEngine() {
    // Tạo builder
    auto builder = std::unique_ptr<nvinfer1::IBuilder, InferDeleter>(
        nvinfer1::createInferBuilder(mLogger));
    if (!builder) {
        std::cerr << "Failed to create TensorRT builder" << std::endl;
        return false;
    }
    
    // Tạo network
    const auto explicitBatch = 1U << static_cast<uint32_t>(nvinfer1::NetworkDefinitionCreationFlag::kEXPLICIT_BATCH);
    auto network = std::unique_ptr<nvinfer1::INetworkDefinition, InferDeleter>(
        builder->createNetworkV2(explicitBatch));
    if (!network) {
        std::cerr << "Failed to create TensorRT network" << std::endl;
        return false;
    }
    
    // Tạo config
    auto config = std::unique_ptr<nvinfer1::IBuilderConfig, InferDeleter>(
        builder->createBuilderConfig());
    if (!config) {
        std::cerr << "Failed to create TensorRT builder config" << std::endl;
        return false;
    }
    
    // Tạo ONNX parser
    auto parser = std::unique_ptr<nvonnxparser::IParser, InferDeleter>(
        nvonnxparser::createParser(*network, mLogger));
    if (!parser) {
        std::cerr << "Failed to create ONNX parser" << std::endl;
        return false;
    }
    
    // Parse ONNX model
    if (!parser->parseFromFile(mModelPath.c_str(), static_cast<int>(nvinfer1::ILogger::Severity::kWARNING))) {
        std::cerr << "Failed to parse ONNX model" << std::endl;
        return false;
    }
    
    // Thiết lập workspace size và FP16 mode (tùy chọn)
    config->setMaxWorkspaceSize(1 << 28); // 256 MiB
    config->setFlag(nvinfer1::BuilderFlag::kFP16);
    // Build engine trực tiếp (TensorRT < 8)
    mEngine = std::shared_ptr<nvinfer1::ICudaEngine>(
    	builder->buildEngineWithConfig(*network, *config), InferDeleter());
    if (!mEngine) {
    	std::cerr << "Failed to build TensorRT engine" << std::endl;
    	return false;
    } 
    
    // Tạo execution context
    mContext = std::shared_ptr<nvinfer1::IExecutionContext>(
        mEngine->createExecutionContext(), InferDeleter());
    if (!mContext) {
        std::cerr << "Failed to create execution context" << std::endl;
        return false;
    }
    
    return true;
}

bool ONNXDetector::preprocessImage(const cv::Mat& frame) {
    cv::Mat resized;
    cv::resize(frame, resized, cv::Size(mInputW, mInputH));
    
    // Chuyển đổi từ BGR sang RGB và normalize
    cv::Mat floatImg;
    resized.convertTo(floatImg, CV_32FC3, 1.0/127.5, -1.0);
    
    // Sắp xếp lại thành NCHW format (TensorRT yêu cầu)
    // SSD MobileNet có thể yêu cầu định dạng NHWC, cần kiểm tra thông số mô hình
    std::vector<cv::Mat> channels;
    cv::split(floatImg, channels);
    
    size_t channelSize = mInputH * mInputW;
    for (int c = 0; c < mInputC; c++) {
        std::memcpy(mHostInputBuffer.data() + c * channelSize, 
                   channels[c].data, channelSize * sizeof(float));
    }
    
    // Copy từ host sang device
    cudaMemcpyAsync(mCudaBuffer[0], mHostInputBuffer.data(), 
                   mInputSize * sizeof(float), cudaMemcpyHostToDevice, mCudaStream);
    
    return true;
}

std::vector<Detection> ONNXDetector::postprocessResults() {
    std::vector<Detection> detections;
    
    // SSD MobileNet output format là [image_id, label, confidence, xmin, ymin, xmax, ymax]
    // cho mỗi detection
    for (size_t i = 0; i < mOutputSize; i += 7) {
        float confidence = mHostOutputBuffer[i+2];
        
        // Lọc theo ngưỡng confidence
        if (confidence > mConfThreshold) {
            Detection det;
            det.classId = static_cast<int>(mHostOutputBuffer[i+1]);
            det.confidence = confidence;
            
            // Tọa độ normalized (0-1)
            det.xmin = mHostOutputBuffer[i+3];
            det.ymin = mHostOutputBuffer[i+4];
            det.xmax = mHostOutputBuffer[i+5];
            det.ymax = mHostOutputBuffer[i+6];
            
            // Thêm tên class
            if (det.classId < mClassNames.size()) {
                det.className = mClassNames[det.classId];
            } else {
                det.className = "Unknown";
            }
            
            detections.push_back(det);
        }
    }
    
    return detections;
}

std::vector<Detection> ONNXDetector::detect(const cv::Mat& frame) {
    // Tiền xử lý hình ảnh
    if (!preprocessImage(frame)) {
        return {};
    }
    
    // Thiết lập input và output
    void* bindings[] = {mCudaBuffer[0], mCudaBuffer[1]};
    
    // Thực hiện inference
    bool status = mContext->executeV2(bindings);
    if (!status) {
        std::cerr << "TensorRT inference failed" << std::endl;
        return {};
    }
    
    // Copy kết quả từ device về host
    cudaMemcpyAsync(mHostOutputBuffer.data(), mCudaBuffer[1], 
                   mOutputSize * sizeof(float), cudaMemcpyDeviceToHost, mCudaStream);
    
    // Đồng bộ hóa
    cudaStreamSynchronize(mCudaStream);
    
    // Xử lý kết quả
    return postprocessResults();
}

void ONNXDetector::drawDetections(cv::Mat& frame, const std::vector<Detection>& detections) {
    for (const auto& det : detections) {
        // Chuyển từ normalized coordinates (0-1) sang pixel coordinates
        int xmin = static_cast<int>(det.xmin * frame.cols);
        int ymin = static_cast<int>(det.ymin * frame.rows);
        int xmax = static_cast<int>(det.xmax * frame.cols);
        int ymax = static_cast<int>(det.ymax * frame.rows);
        
        // Vẽ bounding box
        cv::rectangle(frame, cv::Point(xmin, ymin), cv::Point(xmax, ymax), cv::Scalar(0, 255, 0), 2);
        
        // Tạo nhãn
        std::string label = det.className + " " + std::to_string(det.confidence).substr(0, 4);
        
        // Vẽ nhãn
        int baseline = 0;
        cv::Size textSize = cv::getTextSize(label, cv::FONT_HERSHEY_SIMPLEX, 0.5, 1, &baseline);
        cv::rectangle(frame, cv::Point(xmin, ymin - textSize.height - 5),
                     cv::Point(xmin + textSize.width, ymin),
                     cv::Scalar(0, 255, 0), cv::FILLED);
        cv::putText(frame, label, cv::Point(xmin, ymin - 5),
                   cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0), 1);
    }
}

void ONNXDetector::loadClassNames(const std::string& filename) {
    std::ifstream file(filename);
    if (!file.is_open()) {
        std::cerr << "Failed to open labels file: " << filename << std::endl;
        return;
    }
    
    std::string line;
    while (std::getline(file, line)) {
        mClassNames.push_back(line);
    }
}
